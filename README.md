# Система оценки экзаменационных ответов

Система принимает на вход csv-файл с незаполненным столбцом оценки экзаменатора. На выходе система отдает этот же файл с заполненным столбцом оценкой экзаменатора. 

Дополнительно выводим комментарий к выставлению оценки.

Также к вопросам с описанием картинки в отдельном столбце выводим текст, полученный моделью машинного обучения с картинки вопроса. 

## Предобработка

Берем все неповторяющиеся картинки из вопросов тестового датасета.

С помощью модели BLIP ("Salesforce/blip-image-captioning-base") извлекаем из картинок их описание на английском языке. Далее с помощью переводчика ("Helsinki-NLP/opus-mt-en-ru") переводим текстовое описание на русский язык. 

Сохраняем этот код ("image_caption_dataset.py") и таблицу ("image_captions.csv"). Таблицу мы будем использовать в программе уже в готовом виде.

Первые 3 строки таблицы с картинками и распознаным текстом:
| Картинка из вопроса | caption_ru |
|---------------------|------------|
| https://storage-public.odin.study/37a54d41-aade-4da2-a13d-6ab7d3ef8035.PNG | Семья ест вместе на кухне. |
| https://storage-public.odin.study/8e72cc01-6efb-45ea-b2e7-7999291212da.PNG | карикатура с людьми, играющими в парке |
| https://storage-public.odin.study/c247267a-5a7f-46cc-89fe-8c5961573470.PNG | живопись людей и собак на улице |


## Пайплайн обработки

### 1) Добавление столбца с текстом из картинок в датафрейм

Подтягиваем к основному датафрейму по URL картики ее распознанный текст в новый столбец.

### 2) Транскрибация текста

По умолчанию используем транскрибацию, данную в файле.
Можем транскрибировать с помощью [t-one](https://github.com/voicekit-team/T-one). Он работает на CPU, поэтому достаточно долго. По этой причине по умолчанию он отключен.

### 3) Очистка текста

Очищаем столбцы с транскрибацией вопроса и ответа экзаменуемого от подстрок с "мусором" (HTML-теги, шаблонные фразы не относящиеся к теме вопроса и тд).
Добавляем два новых столбца с очищенными данными в датафрейм.

Можно добавить поддержку регулярных выражений.

### 4) Извлечение признаков и обучение модели

Извлекаем простые текстовые признаки(длины вопроса/ответа/текста с картинок, Jaccard(вопрос, ответ), Jaccard(текст_картинки, ответ))

Для определения степени сходства текстов вопроса и ответа экзаменуемого используем Jaccard Similarity — меру сходства двух множеств слов.

### 5) Обучение/Загрузка модели

Если файла с моделью на диске нет (`output_data\model.pkl`) и в таблице присутствует истинная оценка экзаменатора, то модель обучится на этих данных и запишет файл с моделью на диск.

Обучаем базовую ML-модель (GradientBoostingRegressor) для прогнозирования оценки экзаменуемого. 

Можно использовать более тяжелые модели (BERT, Transformer или LLM), но их использование потребует больше вычислительных мощностей.

Делаем предсказания на новых данных

### 6) Выставляем оценки и добавляем комментарии

Вычисляем оценки при помощи модели.

Проставляем комментарии на основе критериев:

- выполнена ли коммуникативная задача (есть ли смысловые пересечения с вопросом или с текстом с картинки)

- присутсвуют ли полные предложения(слов в предложении >=10)

### 7) Сохранение артефактов

Считает MAE в баллах по всей выборке и по каждому номеру вопроса.

Сохраняем итоговый файл.

## Запуск проекта

- Установка [uv](https://docs.astral.sh/uv/getting-started/installation) (кроссплатформенный пакетный менеджер, который сам установит нужную версию питона и все зависимости):

    - Linux/Mac

    `curl -LsSf https://astral.sh/uv/install.sh | sh`

    - Windows

    `powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"`


- запустить скрипт программы

`uv run main.py`

- запустить веб-сервис

`uv run app.py`

- запустить продакшен веб-сервис

`uv run run_production.py`

